{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac87633-3f22-4890-b4ad-5491919a82ce",
   "metadata": {},
   "source": [
    "# 第一问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e477a5b-bc6a-4a09-bb2b-02d98e45cc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import breeze.linalg._\r\n",
       "import org.apache.spark.mllib.regression.LabeledPoint\r\n",
       "import org.apache.spark.mllib.regression.LinearRegressionWithSGD\r\n",
       "import org.apache.spark.mllib.regression.LinearRegressionModel\r\n",
       "import org.apache.spark.mllib.optimization.{LBFGS, LeastSquaresGradient, SquaredL2Updater}\r\n",
       "import org.apache.spark.mllib.linalg.Vectors\r\n",
       "import breeze.numerics._\r\n",
       "import breeze.stats.distributions._\r\n",
       "import java.util.concurrent.ThreadLocalRandom\r\n",
       "import org.apache.spark.mllib.util.MLUtils\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import breeze.linalg._\n",
    "import org.apache.spark.mllib.regression.LabeledPoint\n",
    "import org.apache.spark.mllib.regression.LinearRegressionWithSGD\n",
    "import org.apache.spark.mllib.regression.LinearRegressionModel\n",
    "import org.apache.spark.mllib.optimization.{LBFGS,LeastSquaresGradient,SquaredL2Updater}\n",
    "import org.apache.spark.mllib.linalg.Vectors\n",
    "import breeze.numerics._\n",
    "import breeze.stats.distributions._\n",
    "import java.util.concurrent.ThreadLocalRandom\n",
    "import org.apache.spark.mllib.util.MLUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a579e4df-3aa1-4094-aabe-abe274a6e841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[18] at map at MLUtils.scala:86\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data=MLUtils.loadLibSVMFile(sc,\"sample_linear_regression_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b776ff-5ef1-4004-a1b5-37bd962aa008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training: org.apache.spark.rdd.RDD[(Double, org.apache.spark.mllib.linalg.Vector)] = MapPartitionsRDD[19] at map at <console>:40\r\n",
       "numFeatures: Int = 10\r\n",
       "numCorrections: Int = 10\r\n",
       "convergenceTol: Double = 1.0E-4\r\n",
       "maxNumIterations: Int = 20\r\n",
       "regParam: Double = 1.0\r\n",
       "initialWeightsWithIntercept: org.apache.spark.mllib.linalg.Vector = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val training=data.map(x => (x.label,MLUtils.appendBias(x.features))).cache()\n",
    "val numFeatures=data.collect()(0).features.size\n",
    "val numCorrections = 10\n",
    "val convergenceTol = 1e-4\n",
    "val maxNumIterations = 20\n",
    "val regParam=1.0\n",
    "val initialWeightsWithIntercept=Vectors.dense(new Array[Double](numFeatures+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c1d242-f303-4b51-82ff-0c525fea135c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weightsWithIntercept0: org.apache.spark.mllib.linalg.Vector = [0.022917619144397203,0.16223861427526343,-0.1839044620018147,0.5454078186017856,0.10941974938462558,0.2811178300566573,-0.09271590011136743,-0.12330860139641511,-0.15505995633811184,0.16156545814727047,0.11614360033051634]\r\n",
       "loss: Array[Double] = Array(53.156115128976595, 52.86141046393933, 52.801233318674036, 52.80046016202687, 52.8004497573181)\r\n",
       "coefficients: breeze.linalg.DenseVector[Double] = DenseVector(0.022917619144397203, 0.16223861427526343, -0.1839044620018147, 0.5454078186017856, 0.10941974938462558, 0.2811178300566573, -0.09271590011136743, -0.12330860139641511, -0.15505995633811184, 0.16156545814727047)\r\n",
       "Intercept: Double = 0.11614360033051634\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//岭回归估计\n",
    "val (weightsWithIntercept0,loss)=LBFGS.runLBFGS(\n",
    "    training,\n",
    "    new LeastSquaresGradient(),\n",
    "    new SquaredL2Updater(),\n",
    "    numCorrections,\n",
    "    convergenceTol,\n",
    "    maxNumIterations,\n",
    "    regParam,\n",
    "    initialWeightsWithIntercept\n",
    ")\n",
    "val coefficients=DenseVector(weightsWithIntercept0.toArray.slice(0,weightsWithIntercept0.size-1))\n",
    "val Intercept=weightsWithIntercept0(weightsWithIntercept0.size-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e07718b-1110-4d21-aa54-97032b8f0823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "betahats: Array[breeze.linalg.DenseVector[Double]] = Array(DenseVector(-0.2805599034020159, 0.33807414484743736, 0.06559608711218212, -0.18649334394513623, -0.29177801427882877, -0.43766083326519123, -0.05703882742319139, -0.04497485193159376, -0.11867991837890113, 0.09039477754318948, -0.020910602766851208), DenseVector(-0.2548111624070867, 0.10254476418460581, 0.03265276847591169, -0.05072414893948031, -0.09547653357836353, -3.601175286412553E-4, -0.062083735827519713, 0.0694909079975895, -0.05323463065776419, 0.22735334686003567, -0.11156685817712772), DenseVector(0.05522937651961185, -0.2914028647502076, 0.020205810545531094, 0.08391226539368733, 0.23325369602793924, 0.23652786189500802, -0.0042941726495931394, -0.3692566581195485, -0.1880354619334564, -0.05176933844458818, 0.074165...\r\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var betahats=Array.ofDim[DenseVector[Double]](200)\n",
    "for (i <- 0 until 200){\n",
    "    var lines=data.map(line => {\n",
    "        val fitted=DenseVector(line.features.toArray).t*coefficients+Intercept\n",
    "        val residual=line.label-fitted\n",
    "        LabeledPoint(residual,line.features)\n",
    "    })\n",
    "    var transit=lines.map(line => {\n",
    "        val r=ThreadLocalRandom.current\n",
    "        val fitted=DenseVector(line.features.toArray).t*coefficients+Intercept\n",
    "        LabeledPoint(fitted+r.nextGaussian*line.label,line.features)\n",
    "    }) //x.label为伪响应变量观察值\n",
    "    val training=transit.map(x => (x.label,MLUtils.appendBias(x.features))).cache()\n",
    "    val (weightsWithIntercept, loss) = LBFGS.runLBFGS(\n",
    "    training, \n",
    "    new LeastSquaresGradient(),\n",
    "    new SquaredL2Updater(),\n",
    "    numCorrections,\n",
    "    convergenceTol,\n",
    "    maxNumIterations,\n",
    "    regParam,\n",
    "    initialWeightsWithIntercept)\n",
    "    betahats(i)=DenseVector(weightsWithIntercept.toArray)\n",
    "} //得到两百个自举法估计量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7aa4b0a-c1d7-4982-a7d8-5bcf77d02f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "betahats_rdd: org.apache.spark.rdd.RDD[breeze.linalg.DenseVector[Double]] = ParallelCollectionRDD[1528] at parallelize at <console>:41\r\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val betahats_rdd=sc.parallelize(betahats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7467624f-7d4a-48d1-8bd6-27c042c70976",
   "metadata": {},
   "source": [
    "### 自举法估计量的均值为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0fd1146f-3624-46b6-93cf-d9306781712a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "betahats_mean: breeze.linalg.DenseVector[Double] = DenseVector(0.008566480315405267, 0.027658175007058333, -0.054718089885915526, 0.11490979180051414, 0.019363874510219772, 0.05422790460686631, -0.04401666788122911, -0.02106770396777516, -0.06287508081965879, 0.0385205309750994, 0.08074881139597843)\r\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val betahats_mean=betahats_rdd.reduce((x,y)=>x+y)/200.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4063ca7d-c2ad-4ab9-b5f5-8a44581eb299",
   "metadata": {},
   "source": [
    "### 自举法估计量的标准差为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49d1eb98-afb5-4972-90f1-40621b2d2d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "betahats_se: breeze.linalg.DenseVector[Double] = DenseVector(0.20907782368152408, 0.2073752759402651, 0.19998917910913824, 0.20056089129032786, 0.1939804476748882, 0.19464284001815577, 0.19282647183311324, 0.19231539460441685, 0.19876088850609688, 0.19822669634328483, 0.22900941961414822)\r\n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val betahats_se=sqrt(betahats_rdd.map(s=>s-betahats_mean).map(s=>s*s).reduce((x,y)=>x+y)/199.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
